# Project Description

The notebook is structured into the following sections:

1. **Libraries Import**
   - Import necessary libraries

2. Load and explore data
   - Load training and test datasets
   - Visualize and clean data
   - Analyze feature distributions and correlations

2. **Data pre-processing**
   - Preprocess features for fitting models
        - include encoding and scaling of features

3. **Model Training**
   - Data is split into training and test sets
   - Models are trained
   - Models are optimized via GridSearch

4. **Evaluation**
   - Evaluate models using different metrics
   - Visualize model predictions and compare with actual outcomes with ConfusionMatrix


## How to Run
1. Clone this repository
2. Move to software_and_data folder
   ```bash
   cd software_and_data
3. Install required packages:
   ```bash
   pip install requirements.txt
4. Run the notebook main.ipynb in Jupyter or VScode
